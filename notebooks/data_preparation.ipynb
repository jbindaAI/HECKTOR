{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6aba4b6-d414-4cbe-bac8-714ccb716037",
   "metadata": {},
   "source": [
    "# Splitting HECKTOR Dataset into folds\n",
    "I filter out problematic examples and split train set into 5 CV train/val sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6925a2e-0e54-446e-8321-294e13891720",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba710b0a-4743-48ca-8c02-005680d6c694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining data paths:\n",
    "MODE = \"test_data\"\n",
    "\n",
    "if MODE == \"test_data\": \n",
    "    endpoint = pd.read_csv(\"/home/jakub/research/HECKTOR/Data/raw_data/hecktor2022/hecktor2022_testing/hecktor2022_endpoint_testing.csv\")\n",
    "    labels_path = \"/home/jakub/research/HECKTOR/Data/filtered_labels/test_labels\"\n",
    "\n",
    "elif MODE == \"train_data\":  \n",
    "    endpoint = pd.read_csv(\"/home/jakub/research/HECKTOR/Data/raw_data/hecktor2022/hecktor2022_training/hecktor2022_patient_endpoint_training.csv\")\n",
    "    labels_path = \"/home/jakub/research/HECKTOR/Data/filtered_labels/train_labels\"\n",
    "\n",
    "os.makedirs(labels_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b707e29b-412f-474d-9469-747b5c432986",
   "metadata": {},
   "source": [
    "## Splitting data into 5CV folds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c8e881-20d4-4798-922a-e05b1898de9b",
   "metadata": {},
   "source": [
    "Some examples are corrupted. In particular, there are examples with broken files -> with zeroed slices.\n",
    "Also there are files which don't include mask labels corresponding to GTVp (primary Gross Tumor Volume). Such files were ommited and are listed below:|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7923a1f-d540-4c98-b755-dc2ad3779f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "problematic_train_files = [\n",
    "    \"CHUM-016\",\n",
    "    \"CHUM-029\",\n",
    "    \"CHUM-065\",\n",
    "    \"CHUP-029\",\n",
    "    \"CHUP-032\",\n",
    "    \"CHUS-076\",\n",
    "    \"CHUV-008\",\n",
    "    \"MDA-029\",\n",
    "    \"MDA-036\",\n",
    "    \"MDA-048\",\n",
    "    \"MDA-061\",\n",
    "    \"MDA-091\",\n",
    "    \"MDA-107\",\n",
    "    \"MDA-121\",\n",
    "    \"MDA-124\",\n",
    "    \"MDA-128\",\n",
    "    \"MDA-166\",\n",
    "    \"MDA-169\",\n",
    "    \"MDA-179\",\n",
    "    \"MDA-180\",\n",
    "    \"MDA-192\",\n",
    "    \"MDA-200\",\n",
    "    \"MDA-201\"\n",
    "]\n",
    "\n",
    "problematic_test_files = [\n",
    "    \"MDA-270\",\n",
    "    \"MDA-298\",\n",
    "    \"MDA-308\",\n",
    "    \"MDA-309\",\n",
    "    \"MDA-310\",\n",
    "    \"MDA-319\",\n",
    "    \"MDA-363\",\n",
    "    \"MDA-368\",\n",
    "    \"MDA-375\",\n",
    "    \"MDA-381\",\n",
    "    \"MDA-382\",\n",
    "    \"MDA-388\",\n",
    "    \"MDA-392\",\n",
    "    \"CHB-013\",\n",
    "    \"CHB-017\",\n",
    "    \"CHB-026\",\n",
    "    \"CHB-040\",\n",
    "    \"CHB-058\"\n",
    "]\n",
    "\n",
    "if MODE == \"train_data\":\n",
    "    endpoint_filtered=endpoint[~endpoint['PatientID'].isin(problematic_train_files)]\n",
    "    endpoint_filtered.to_csv(os.path.join(labels_path, \"train_labels_filtered.csv\"))\n",
    "\n",
    "    # Save one fold with all train data\n",
    "    with open(os.path.join(labels_path, f\"train_fold_all.pkl\"), 'wb') as file:\n",
    "        train_indices=list(range(len(endpoint_filtered[\"PatientID\"])))\n",
    "        pickle.dump(train_indices, file)\n",
    "    \n",
    "    # Split data into 5CV and save train/val folds\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    folds = skf.split(X=endpoint_filtered[\"PatientID\"], y=endpoint_filtered[\"Relapse\"])\n",
    "\n",
    "    for i, (train_indices, val_indices) in enumerate(folds):\n",
    "        with open(os.path.join(labels_path, f\"train_fold_{i+1}.pkl\"), 'wb') as file:\n",
    "            pickle.dump(list(train_indices), file)\n",
    "        with open(os.path.join(labels_path, f\"val_fold_{i+1}.pkl\"), 'wb') as file:\n",
    "            pickle.dump(list(val_indices), file)\n",
    "else:\n",
    "    endpoint_filtered=endpoint[~endpoint['PatientID'].isin(problematic_test_files)]\n",
    "    endpoint_filtered.to_csv(os.path.join(labels_path, \"test_labels_filtered.csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
